{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import DBSCAN, MeanShift\n",
    "from sklearn.metrics import pairwise_distances\n",
    "import seaborn as sns\n",
    "\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('adel.xlsx', sheet_name=1, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_columns = ['v' + str(x) for x in range(9, 22)]\n",
    "desired_columns.append('v24')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[desired_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eps = 18.599999999999994\n",
      "labels = [-1  0  1  2]\n",
      "number of individual clusters = 60\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Cluster|# Points\n",
       "---:|:---\n",
       "-1|60\n",
       "0|541\n",
       "1|3\n",
       "2|14\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eps = 0.5\n",
    "\n",
    "while True:\n",
    "    labels = DBSCAN(eps=eps).fit_predict(df)\n",
    "    if sum(labels == -1) <= 60:\n",
    "        break\n",
    "    \n",
    "    eps += 0.1\n",
    "\n",
    "print('eps =', eps)\n",
    "print('labels =', np.unique(labels))\n",
    "print('number of individual clusters =', sum(labels == -1))\n",
    "\n",
    "table = 'Cluster|# Points\\n---:|:---\\n'\n",
    "for i in range(len(np.unique(labels))):\n",
    "    table += str(i-1) + '|'  # To account for -1\n",
    "    table += str(sum(labels == i-1))\n",
    "    table += '\\n'\n",
    "\n",
    "display(Markdown(table))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = {}\n",
    "\n",
    "for i in range(-1, 3):\n",
    "    indices[i] = np.where(labels == i)[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{-1: array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
       "         13,  14,  15,  16,  17,  18,  19,  20,  23,  24,  26,  27,  28,\n",
       "         30,  31,  35,  38,  39,  41,  42,  44,  48,  50,  52,  55,  58,\n",
       "         60,  61,  63,  64,  66,  68,  69,  78,  98, 100, 109, 115, 131,\n",
       "        142, 182, 202, 203, 208, 217, 254, 392]),\n",
       " 0: array([ 21,  22,  25,  32,  34,  36,  37,  40,  43,  46,  47,  49,  53,\n",
       "         54,  57,  59,  62,  65,  67,  70,  73,  74,  75,  77,  79,  80,\n",
       "         81,  82,  83,  84,  85,  86,  88,  89,  90,  91,  92,  93,  94,\n",
       "         95,  96,  97,  99, 101, 102, 103, 106, 107, 108, 110, 111, 112,\n",
       "        113, 114, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127,\n",
       "        128, 129, 130, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
       "        143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
       "        157, 158, 160, 161, 162, 163, 164, 166, 167, 168, 169, 170, 171,\n",
       "        172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 183, 184, 185,\n",
       "        186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198,\n",
       "        199, 200, 201, 204, 205, 206, 207, 209, 210, 211, 213, 214, 215,\n",
       "        216, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229,\n",
       "        230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242,\n",
       "        243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 255, 256,\n",
       "        257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269,\n",
       "        270, 271, 272, 273, 274, 275, 276, 277, 279, 280, 281, 282, 283,\n",
       "        284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296,\n",
       "        297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309,\n",
       "        310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322,\n",
       "        323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335,\n",
       "        336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348,\n",
       "        349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361,\n",
       "        362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374,\n",
       "        375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387,\n",
       "        388, 389, 390, 391, 393, 394, 395, 396, 397, 398, 399, 400, 401,\n",
       "        402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414,\n",
       "        415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427,\n",
       "        428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440,\n",
       "        441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453,\n",
       "        454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466,\n",
       "        467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479,\n",
       "        480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492,\n",
       "        493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505,\n",
       "        506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518,\n",
       "        519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531,\n",
       "        532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544,\n",
       "        545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557,\n",
       "        558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570,\n",
       "        571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583,\n",
       "        584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596,\n",
       "        597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609,\n",
       "        610, 611, 612, 613, 614, 615, 616, 617]),\n",
       " 1: array([29, 33, 45]),\n",
       " 2: array([ 51,  56,  71,  72,  76,  87, 104, 105, 116, 156, 159, 165, 212,\n",
       "        278])}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean Shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n"
     ]
    }
   ],
   "source": [
    "ms = MeanShift()\n",
    "preds = ms.fit_predict(df)\n",
    "print(np.unique(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Cluster|# Points\n",
       "---:|:---\n",
       "0|504\n",
       "1|82\n",
       "2|15\n",
       "3|3\n",
       "4|2\n",
       "5|2\n",
       "6|2\n",
       "7|1\n",
       "8|1\n",
       "9|1\n",
       "10|1\n",
       "11|1\n",
       "12|1\n",
       "13|1\n",
       "14|1\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "table = 'Cluster|# Points\\n---:|:---\\n'\n",
    "for i in range(15):\n",
    "    table += str(i) + '|'\n",
    "    table += str(sum(preds == i))\n",
    "    table += '\\n'\n",
    "\n",
    "display(Markdown(table))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "indiv_indices = np.where(preds >= 7)[0]\n",
    "preds[indiv_indices] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1  0  1  2  3  4  5  6]\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Cluster|# Points\n",
       "---:|:---\n",
       "-1|8\n",
       "0|504\n",
       "1|82\n",
       "2|15\n",
       "3|3\n",
       "4|2\n",
       "5|2\n",
       "6|2\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "table = 'Cluster|# Points\\n---:|:---\\n'\n",
    "for i in range(-1, 7):\n",
    "    table += str(i) + '|'\n",
    "    table += str(sum(preds == i))\n",
    "    table += '\\n'\n",
    "\n",
    "display(Markdown(table))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "504\n"
     ]
    }
   ],
   "source": [
    "# Check the 504/541 points\n",
    "dbs_indices = np.where(labels == 0)[0]\n",
    "ms_indices = np.where(preds == 0)[0]\n",
    "\n",
    "print(len(set(dbs_indices).intersection(ms_indices)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# Double-check this result!!\n",
    "print(all([x in dbs_indices for x in ms_indices]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37\n"
     ]
    }
   ],
   "source": [
    "# Check the 541/82 points\n",
    "dbs_indices = np.where(labels == 0)[0]\n",
    "ms_indices = np.where(preds == 1)[0]\n",
    "\n",
    "print(len(set(dbs_indices).intersection(ms_indices)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n"
     ]
    }
   ],
   "source": [
    "# Check the 82/60 points\n",
    "dbs_indices = np.where(labels == -1)[0]\n",
    "ms_indices = np.where(preds == 1)[0]\n",
    "\n",
    "print(len(set(dbs_indices).intersection(ms_indices)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means that 28 points that were individual clusters according to DBSCAN were a part of a cluster according to Mean Shift."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    }
   ],
   "source": [
    "# Check the 82/14 points\n",
    "dbs_indices = np.where(labels == 2)[0]\n",
    "ms_indices = np.where(preds == 1)[0]\n",
    "\n",
    "print(len(set(dbs_indices).intersection(ms_indices)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means that apart from the 28 that were marked by DBSCAN as individual clusters, all 14 points that it had marked as one cluster were also part of this cluster of 82 points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "# Check the 82/3 points\n",
    "dbs_indices = np.where(labels == 1)[0]\n",
    "ms_indices = np.where(preds == 1)[0]\n",
    "\n",
    "print(len(set(dbs_indices).intersection(ms_indices)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To summarize:  \n",
    "\n",
    "* DBSCAN identified 3 clusters, 0-2, and identified 60 points as not belonging to any cluster. This is because of the threshold that we set.\n",
    "* Mean-Shift identified 7 clusters, 0-6, and identified 8 points as not belonging to any cluster.\n",
    "* All of the MS cluster 0 points were a part of DBSCAN cluster 0.\n",
    "* Out of 82, 37 of MS cluster 1 points were also a part of DBSCAN cluster 0  \n",
    "\n",
    "We'll put the full summary in a table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Index|DBSCAN cluster#|MS cluster#|DBSCAN cluster count|MS cluster count|Common\n",
       "---|:---:|:---:|:---:|:---:|---\n",
       "1|-1|-1|60|8|8\n",
       "2|-1|1|60|82|28\n",
       "3|-1|2|60|15|15\n",
       "4|-1|3|60|3|3\n",
       "5|-1|4|60|2|2\n",
       "6|-1|5|60|2|2\n",
       "7|-1|6|60|2|2\n",
       "8|0|0|541|504|504\n",
       "9|0|1|541|82|37\n",
       "10|1|1|3|82|3\n",
       "11|2|1|14|82|14\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "table = 'Index|DBSCAN cluster#|MS cluster#|DBSCAN cluster count|MS cluster count|Common\\n---|:---:|:---:|:---:|:---:|---\\n'\n",
    "index = 1\n",
    "\n",
    "for i in range(-1, 3):\n",
    "    dbs_count = len(np.where(labels == i)[0])\n",
    "    \n",
    "    for j in range(-1, 7):\n",
    "        ms_count = len(np.where(preds == j)[0])\n",
    "        \n",
    "        dbs_indices = np.where(labels == i)[0]\n",
    "        ms_indices = np.where(preds == j)[0]\n",
    "        \n",
    "        common = len(set(dbs_indices).intersection(ms_indices))\n",
    "        \n",
    "        if common > 0:\n",
    "            table += '{0}|{1}|{2}|{3}|{4}|{5}\\n'.format(index, i, j, dbs_count, ms_count, common)\n",
    "            index += 1\n",
    "\n",
    "display(Markdown(table))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So an English summary is as follows.  \n",
    "\n",
    "* **Individual clusters discussion:** \n",
    "  * Because of our threshold, DBSCAN marked 60 points as individual clusters. Mean-Shift marked only 8 such points **(row 1)**\n",
    "  * However, Mean-Shift marked 4 other clusters that had 3 or less points. All points marked by Mean-Shift as having 3 or less points were a part of DBSCAN's individual clusters **(rows 4-7)**. \n",
    "  * More surprisingly, a cluster marked by Mean-Shift as having 15 points was marked by DBSCAN as 15 individual clusters **(row 3)**. So far, we've accounted for 32/60 of DBSCAN's individual clusters. \n",
    "  * The rest of the 28 come from Mean-Shift's second largest cluster of 82 points **(row 2)**. This analysis may suggest that we should lower the threshold for DBSCAN, or *increase* `eps`.\n",
    "* **Largest clusters discussion:**\n",
    "  * Mean-Shift's largest cluster had 504 points. This cluster was a proper subset of DBSCAN's largest subset of 541 points **(row 8)**.\n",
    "  * A large part of Mean-Shift's second-largest cluster, 37/82 points, was also absorbed by DBSCAN's largest cluster **(row 9)**. \n",
    "  * Perhaps reducing `eps` might make DBSCAN's clusters smaller, and make both the clustering algorithms' outputs more similar. While this seems to contradict an earlier point, these are in fact two separate observations. Increasing `eps` would mean DBSCAN would find less clusters as single points. Decreasing `eps` would certainly increase that, which we do not want, but would shift some points in the larger clusters around, which may be desirable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding \"prolific\" authors using DBSCAN clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster 0 and cluster 2 (biggest and second-biggest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbs0 = df.iloc[np.where(labels == 0)[0],:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "v9      5.127542\n",
       "v10     9.171904\n",
       "v11     3.994455\n",
       "v12     1.908170\n",
       "v13     3.430684\n",
       "v14    22.172606\n",
       "v15     3.789593\n",
       "v16     8.525139\n",
       "v17     7.510222\n",
       "v18     2.900924\n",
       "v19     4.071405\n",
       "v20     0.216147\n",
       "v21     0.249316\n",
       "v24     0.240296\n",
       "dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbs0.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbs2 = df.iloc[np.where(labels == 2)[0],:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "v9      16.857143\n",
       "v10     32.642857\n",
       "v11     12.642857\n",
       "v12      4.439286\n",
       "v13      9.785714\n",
       "v14    157.159286\n",
       "v15     12.535000\n",
       "v16     44.418571\n",
       "v17     28.739286\n",
       "v18      7.440000\n",
       "v19     18.269286\n",
       "v20      0.352442\n",
       "v21      0.481429\n",
       "v24      4.214286\n",
       "dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbs2.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "pvalues = st.ttest_ind(dbs0, dbs2, equal_var=False)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all(pvalues <= 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "v9      24.383333\n",
       "v10     46.716667\n",
       "v11     15.566667\n",
       "v12      8.383833\n",
       "v13     15.433333\n",
       "v14    296.113833\n",
       "v15     16.244833\n",
       "v16    108.879333\n",
       "v17     37.859000\n",
       "v18     13.961500\n",
       "v19     43.061000\n",
       "v20      0.615387\n",
       "v21      0.597667\n",
       "v24      5.650000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbs_ind = df.iloc[np.where(labels == -1)[0],:]\n",
    "dbs_ind.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster 0 and cluster 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbs1 = df.iloc[np.where(labels == 1)[0],:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "pvalues = st.ttest_ind(dbs0, dbs1, equal_var=False)[1]\n",
    "print(all(pvalues <= 0.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7857142857142857\n"
     ]
    }
   ],
   "source": [
    "print(sum(pvalues <= 0.05) / len(pvalues))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10/14 p-values are statistically significant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Cluster 1|Cluster 2|95% significant|90% significant\n",
       "---:|:---:|:---:|:---\n",
       "-1|0|1.0|1.0\n",
       "-1|1|0.8571428571428571|0.8571428571428571\n",
       "-1|2|0.9285714285714286|1.0\n",
       "0|1|0.7857142857142857|0.8571428571428571\n",
       "0|2|1.0|1.0\n",
       "1|2|0.6428571428571429|0.7857142857142857\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "table = 'Cluster 1|Cluster 2|95% significant|90% significant\\n---:|:---:|:---:|:---\\n'\n",
    "\n",
    "for i in range(-1, 3):\n",
    "    dbs_i =  df.iloc[np.where(labels == i)[0],:]\n",
    "    \n",
    "    for j in range(i+1, 3):\n",
    "        dbs_j = df.iloc[np.where(labels == j)[0],:]\n",
    "        \n",
    "        pvalues_95 = st.ttest_ind(dbs_i, dbs_j, equal_var=False)[1]\n",
    "        per_significant_95 = sum(pvalues_95 <= 0.05) / len(pvalues)\n",
    "        \n",
    "        pvalues_90 = st.ttest_ind(dbs_i, dbs_j, equal_var=False)[1]\n",
    "        per_significant_90 = sum(pvalues_90 <= 0.1) / len(pvalues)\n",
    "        table += '{0}|{1}|{2}|{3}\\n'.format(i, j, per_significant_95, per_significant_90)\n",
    "\n",
    "display(Markdown(table))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the biggest cluster and the individual clusters have means that are statistically significant at 95% confidence level. The biggest and second biggest clusters (0 and 2) also have means that are statistically significant at 95% confidence level. For the second biggest and the individual clusters, 13/14 p-values are statistically significant at 95% confidence level, and all of these are at 90% confidence level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5713389151552444"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "silhouette_score(df, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([13])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pvalues_95 = st.ttest_ind(dbs_ind, dbs2, equal_var=False)[1]\n",
    "np.where(pvalues_95 > 0.05)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "python3.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
